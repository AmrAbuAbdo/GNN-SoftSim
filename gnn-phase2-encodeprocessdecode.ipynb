{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of gnn_phase_exp4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECdzhRxjcXt3"
      },
      "source": [
        "# Graph Failure Propagation using Deepmind's GCN Framework - Phase 2\n",
        "\n",
        "\n",
        "This notebook models a network failure propagation scenario using a Graph Neural Network.\n",
        "\n",
        "The framework used is [Google's Deepmind GraphNet Framework](https://github.com/deepmind/graph_nets/)\n",
        "\n",
        "\n",
        "We need to add new boolean features (Latency, Error, Saturated, and Traffic) as below:\n",
        "```\n",
        "Latency = 1 -> there is a latency in the app\n",
        "Latency = 0 -> there is no latency in the app\n",
        "..\n",
        "Error = 1 -> there are errors in the app\n",
        "Error = 0 -> there are errors in the app\n",
        "..\n",
        "Saturated = 1 -> Resources are fully occupied/utilized for that app\n",
        "Saturated = 0 -> Resources are not fully occupied/utilized for that app (there are available resources)\n",
        "..\n",
        "Traffic = 2 -> There is a high amount of traffic hitting that app\n",
        "Traffic = 1 -> There is a med amount of traffic hitting that app\n",
        "Traffic = 0 -> There is a low amount of traffic hitting that app\n",
        "\n",
        "downstreams (Direct Child nodes)\n",
        "upstreams (Direct Parent Nodes)\n",
        "A -> B\n",
        "A is Direct parent of B\n",
        "B is direct child of A\n",
        "\n",
        "Phase 2 Simulator rules:\n",
        "1- High traffic causes Saturation on the same node in the next step.\n",
        "2- Saturation causes immediate low traffic on downstreams in the same step.\n",
        "3- Saturation causes Latency on the same node in the next step.\n",
        "4- Latency causes Latency on the upstreams in the next step.\n",
        "5- Latency causes Errors on the same node in the next step.\n",
        "6- Latency causes Errors on the downstreams in the next step.\n",
        "7- Low traffic causes Low traffic on the downstreams in the next step.\n",
        "8- Errors cause Errors on the downstreams in the next step.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "And then based on an equation like\n",
        "\n",
        "```\n",
        "health = med traffic && !error && !latency && !saturated\n",
        "```\n",
        "\n",
        "The node is healthy if:\n",
        "- there is a medium amount of traffic\n",
        "- no errors \n",
        "- no latency \n",
        "- there are available resources\n",
        "\n",
        "The scenario can be;\n",
        "- if there is a high traffic/low traffic (traffic = 2 / traffic = 0):\n",
        "  1. it will lead to high usage of resources (saturated = 1) at the next step\n",
        "  1. this saturation will cause latency (latency = 1) at the next step \n",
        "  1. eventually (error = 1).\n",
        "\n",
        "we want to be able to predict some of them:\n",
        "- i.e latency and errors ..  \n",
        "- based on that prediction we decide if the node is healthy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvW7y3lQX9Hr"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7xaRNV1uz7q"
      },
      "source": [
        "!pip install -q --upgrade ipython==5.5.0\n",
        "!pip install -q --upgrade ipykernel==4.10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYLeRinwsMDt"
      },
      "source": [
        "try:\n",
        "  %pip install --quiet --user --upgrade watermark \n",
        "  %pip install --quiet --user --upgrade \"graph_nets>=1.1\" \"dm-sonnet>=2.0.0b0\"\n",
        "  import sonnet\n",
        "except ModuleNotFoundError:\n",
        "  import os\n",
        "  print('libraries installed. restarting ...')\n",
        "  os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zR-BuCrsVI5"
      },
      "source": [
        "%load_ext watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hcbwGRbsQa_"
      },
      "source": [
        "%watermark -u -n -t -z -p numpy,tensorflow,sonnet,graph_nets -g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKDbD-gJTgrj"
      },
      "source": [
        "## Configure Environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzWcYNkfcnq-"
      },
      "source": [
        "#@title Imports\n",
        "import time\n",
        "import copy\n",
        "import itertools\n",
        "\n",
        "import tensorflow as tf\n",
        "import networkx as nx\n",
        "import sonnet as snt\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "try:\n",
        "  import seaborn as sns\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  sns.reset_orig()\n",
        "\n",
        "from graph_nets import blocks\n",
        "from graph_nets import utils_tf\n",
        "from graph_nets import utils_np\n",
        "from graph_nets.demos_tf2 import models\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "72Il4Vslc_Gf"
      },
      "source": [
        "#@title Set Random seeds\n",
        "SEED = 42 #@param\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjhyWhA7oC6w"
      },
      "source": [
        "NODE_HEALTH_THRESHOLD = 0.85 # @param\n",
        "EDGE_HEALTH_THRESHOLD = 0.85 # @param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "yaxLLlWXlZMt"
      },
      "source": [
        "#@title Load Graph Visualization Functions\n",
        "\n",
        "def plot_graphs_tuple(graphs_tuple):\n",
        "  networkx_graphs = utils_np.graphs_tuple_to_networkxs(graphs_tuple)\n",
        "  num_graphs = len(networkx_graphs)\n",
        "  _, axes = plt.subplots(1, num_graphs, figsize=(5*num_graphs, 5))\n",
        "  if num_graphs == 1:\n",
        "    axes = axes,\n",
        "  for graph, ax in zip(networkx_graphs, axes):\n",
        "    plot_graph_networkx(graph, ax)\n",
        "\n",
        "import collections\n",
        "\n",
        "NodeStatus = collections.namedtuple('NodeStatus', ['latency', 'errors', 'saturation', 'traffic'])\n",
        "\n",
        "NodeStatus.is_healthy = lambda self: (self.latency == 0 and\n",
        "                                      self.errors == 0 and\n",
        "                                      self.saturation == 0 and\n",
        "                                      self.traffic == 1)\n",
        "\n",
        "EdgeStatus = collections.namedtuple('EdgeStatus', ['latency', 'traffic'])\n",
        "\n",
        "EdgeStatus.is_healthy = lambda self: (self.latency == 0 and\n",
        "                                      self.traffic == 1)\n",
        "def node_status(d):\n",
        "  L, E, S, T = np.argmax(d[0:2]), np.argmax(d[2:4]), np.argmax(d[4:6]), np.argmax(d[6:])\n",
        "  return NodeStatus(L, E, S, T)\n",
        "\n",
        "def edge_status(d):\n",
        "  L, T = np.argmax(d[0:2]), np.argmax(d[2:])\n",
        "  return EdgeStatus(L, T)\n",
        "\n",
        "def nodefmt(node, data):\n",
        "  d = data['features']\n",
        "  L, E, S, T = np.argmax(d[0:2]), np.argmax(d[2:4]), np.argmax(d[4:6]), np.argmax(d[6:])\n",
        "  if (L == 0 and T == 1 and S == 0 and E == 0):\n",
        "    return \"\"\n",
        "  fmt = []\n",
        "  if L:\n",
        "    fmt.append(\"L\") #:{:.2g}\".format(L))\n",
        "  if E:\n",
        "    fmt.append(\"E\") #:{:.2g}\".format(E))\n",
        "  if S:\n",
        "    fmt.append(\"S\") # :{:.2g}\".format(S))\n",
        "  if (T == 0 or T == 2):\n",
        "    fmt.append(\"T:{:.2g}\".format(T))\n",
        "  return \"|\".join(fmt)\n",
        "\n",
        "def edgefmt(sender, receiver, data):\n",
        "  d = data['features']\n",
        "  L, T = np.argmax(d[0:2]), np.argmax(d[2:])\n",
        "  if (L == 0 and T == 1):\n",
        "    return \"\"\n",
        "  fmt = [] \n",
        "  if L:\n",
        "    fmt.append(\"L\") #:{:.2g}\".format(L))\n",
        "  if T:\n",
        "    fmt.append(\"T:{:.2g}\".format(T))\n",
        "  return \"|\".join(fmt)\n",
        "\n",
        "# def is_nhealthy(node, data):\n",
        "#   data = data['features']\n",
        "#   return  np.mean((data[0], data[2], data[4], data[6])) > NODE_HEALTH_THRESHOLD\n",
        "\n",
        "# def is_ehealthy(sender, receiver, data):\n",
        "#   data = data['features']\n",
        "#   return  np.mean((data[0], data[2])) > EDGE_HEALTH_THRESHOLD\n",
        "\n",
        "ORANGE = '#FFD23F'\n",
        "RED = '#EE4266'\n",
        "GREEN = \"g\"\n",
        "\n",
        "def edge_color(sender, receiver, data):\n",
        "  status = edge_status(data['features'])\n",
        " \n",
        "  if status.is_healthy():\n",
        "    return GREEN\n",
        "  \n",
        "  color = GREEN\n",
        "  \n",
        "  if status.latency == 1:   # high latency\n",
        "    color = ORANGE\n",
        "  if status.traffic == 0:   # low traffic\n",
        "    color = ORANGE\n",
        "  elif status.traffic == 2: # high traffic\n",
        "    color = RED\n",
        "  return color\n",
        "\n",
        "def node_color(node, data):\n",
        "  status = node_status(data['features'])\n",
        "\n",
        "  if status.is_healthy():\n",
        "    return GREEN\n",
        "\n",
        "  color = GREEN\n",
        "  if status.latency == 1: # high latency\n",
        "    color = ORANGE\n",
        "  if status.errors == 1: # has error\n",
        "    color = RED\n",
        "    return color\n",
        "  if status.saturation == 1: # saturated\n",
        "    color = ORANGE\n",
        "  if status.traffic == 0: # low traffic\n",
        "    color = ORANGE\n",
        "  elif status.traffic == 2: # high traffic\n",
        "    color = RED\n",
        "  return color\n",
        "\n",
        "def plot_graph_networkx(graph, ax, pos=None):\n",
        "  # node \n",
        "  node_labels = {node: nodefmt(node, data) \n",
        "                  for node, data in graph.nodes(data=True)\n",
        "                    if data[\"features\"] is not None}\n",
        "  # edge\n",
        "  edge_labels = {(sender, receiver): edgefmt(sender, receiver, data) \n",
        "                 for sender, receiver, data in graph.edges(data=True)\n",
        "                 if data[\"features\"] is not None}\n",
        "  # unused\n",
        "  global_label = (\"{:.3g}\".format(graph.graph[\"features\"][0])\n",
        "                  if graph.graph[\"features\"] is not None else None)\n",
        "  \n",
        "  node_color_map = [node_color(node, data) \n",
        "                          for node, data in graph.nodes(data=True)]\n",
        "\n",
        "  edge_color_map = [edge_color(sender, receiver, data) \n",
        "                 for sender, receiver, data in graph.edges(data=True)]\n",
        "  \n",
        "  \n",
        "  if pos is None:\n",
        "    random_pos = nx.random_layout(graph, seed=42)\n",
        "    pos = nx.spring_layout(graph, pos=random_pos)\n",
        "\n",
        "  nx.draw_networkx(graph, pos, ax=ax, \n",
        "                   labels=node_labels,\n",
        "                   edge_color=edge_color_map,\n",
        "                   node_color=node_color_map, node_size=700)\n",
        "\n",
        "  if edge_labels:\n",
        "    nx.draw_networkx_edge_labels(graph, pos, edge_labels, ax=ax)\n",
        "\n",
        "  if global_label:\n",
        "    plt.text(0.05, 0.95, global_label, transform=ax.transAxes)\n",
        "\n",
        "  ax.yaxis.set_visible(False)\n",
        "  ax.xaxis.set_visible(False)\n",
        "  return pos\n",
        "\n",
        "\n",
        "def plot_compare_graphs(graphs_tuples, labels):\n",
        "  pos = None\n",
        "  num_graphs = len(graphs_tuples)\n",
        "  _, axes = plt.subplots(1, num_graphs, figsize=(5*num_graphs, 5))\n",
        "  if num_graphs == 1:\n",
        "    axes = axes,\n",
        "  pos = None\n",
        "  for name, graphs_tuple, ax in zip(labels, graphs_tuples, axes):\n",
        "    graph = utils_np.graphs_tuple_to_networkxs(graphs_tuple)[0]\n",
        "    pos = plot_graph_networkx(graph, ax, pos=pos)\n",
        "    ax.set_title(name)\n",
        "\n",
        "def plot_compare_graphs_custom(graphs_tuples, labels):\n",
        "  pos = None\n",
        "  num_graphs = len(graphs_tuples)\n",
        "  _, axes = plt.subplots(1, num_graphs, figsize=(50*num_graphs, 50))\n",
        "  if num_graphs == 1:\n",
        "    axes = axes,\n",
        "  pos = None\n",
        "  for name, graphs_tuple, ax in zip(labels, graphs_tuples, axes):\n",
        "    graph = utils_np.graphs_tuple_to_networkxs(graphs_tuple)[0]\n",
        "    pos = plot_graph_networkx(graph, ax, pos=pos)\n",
        "    ax.set_title(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XbDHppV53a"
      },
      "source": [
        "# Configure Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzOq2wzCd3sG"
      },
      "source": [
        "#@title Create Graph Dict { form-width: \"30%\" }\n",
        "#@markdown number of features per edge\n",
        "LATENCY = 2\n",
        "ERROR = 2\n",
        "SATURATION = 2\n",
        "TRAFFIC = 3\n",
        "\n",
        "NODE_FEATURES_DIM = LATENCY + ERROR + SATURATION + TRAFFIC \n",
        "\n",
        "EDGES_FEATURES_DIM = LATENCY + TRAFFIC \n",
        "\n",
        "def healthy_node():\n",
        "  return [ 1., # no latency\n",
        "           0.,\n",
        "           1., # no errors\n",
        "           0.,\n",
        "           1., # no saturation\n",
        "           0.,\n",
        "           0., # medium traffic\n",
        "           1.,\n",
        "           0.,   \n",
        "          ]\n",
        "\n",
        "def healthy_edge():\n",
        "  return [\n",
        "          1., # no latency\n",
        "          0.,\n",
        "          0., # medium traffic\n",
        "          1.,\n",
        "          0.]\n",
        "\n",
        "def set_traffic(data, value):\n",
        "  if value == 1:\n",
        "    data[6:] = [0.0, 1.0, 0.0]\n",
        "  elif value == 2:\n",
        "    data[6:] = [0.0, 0.0, 1.0]\n",
        "  else:\n",
        "    data[6:] = [1.0, 0.0, 0.0]\n",
        "  return data\n",
        "\n",
        "def set_saturation(data, value):\n",
        "  if value:\n",
        "    data[4:6] = [0.0, 1.0]\n",
        "  else:\n",
        "    data[4:6] = [1.0, 0.0]\n",
        "  return data\n",
        "\n",
        "def set_error(data, value):\n",
        "  if value:\n",
        "    data[2:4] = [0.0, 1.0]\n",
        "  else:\n",
        "    data[2:4] = [1.0, 0.0]\n",
        "  return data\n",
        "\n",
        "def set_latency(data, value):\n",
        "  if value:\n",
        "    data[0:2] = [0.0, 1.0]\n",
        "  else:\n",
        "    data[0:2] = [1.0, 0.0]\n",
        "  return data\n",
        "\n",
        "def set_edge_traffic(data, value):\n",
        "  if value == 1:\n",
        "    data[2:] = [0.0, 1.0, 0.0]\n",
        "  elif value == 2:\n",
        "    data[2:] = [0.0, 0.0, 1.0]\n",
        "  else:\n",
        "    data[2:] = [1.0, 0.0, 0.0]\n",
        "  return data\n",
        "\n",
        "from random import randrange\n",
        "def create_graph_dict(nodes_n, edges_n, i):\n",
        "\n",
        "  nodes = np.array([ np.array(healthy_node(), dtype=np.float32) for _ in range(nodes_n) ], dtype=np.float32)\n",
        "\n",
        "  # first node is having high latency\n",
        "  # nodes[0][0:2] = [0.0, 1.0]\n",
        "  # first node is having errors\n",
        "  # nodes[0][4:6] = [0.0, 1.0]\n",
        "  \n",
        "  # random=randrange(2) # traffic control\n",
        "  # random2=randrange(4) # issue control\n",
        "\n",
        "  # if random2 == 0:\n",
        "  #   nodes[0][0:2] = [0.0, 1.0] # high latency\n",
        "  # elif random2 == 1:\n",
        "  #   nodes[0][2:4] = [0.0, 1.0] # high saturation\n",
        "  # elif random2 == 2:\n",
        "  #   nodes[0][4:6] = [0.0, 1.0] # high errors\n",
        "  # else: # low/high traffic\n",
        "  #   if random == 1:\n",
        "  #     nodes[0][6:] = [0.0, 0.0, 1.0]\n",
        "  #   else:\n",
        "  #     nodes[0][6:] = [1.0, 0.0, 0.0]\n",
        "  nodes[0][6:] = [1.0, 0.0, 0.0]\n",
        "  # we don't have a global state (for now)\n",
        "  globals_ft = [0.0, 0.0]\n",
        "  \n",
        "  # Edges.\n",
        "  edges, senders, receivers = [], [], []\n",
        "\n",
        "  perm_edges = list(itertools.combinations(np.arange(nodes_n), 2))\n",
        "  idx = np.arange(len(perm_edges)) \n",
        "  np.random.shuffle(idx)\n",
        "\n",
        "  for ix in idx[:edges_n]:\n",
        "    # Left incoming edge.\n",
        "    edges.append(healthy_edge())\n",
        "    a,b = perm_edges[ix]\n",
        "    senders.append(a)\n",
        "    receivers.append(b)\n",
        "\n",
        "  return {\n",
        "      \"globals\": np.array(globals_ft, dtype=np.float64),\n",
        "      \"nodes\": np.array(nodes, dtype=np.float64),\n",
        "      \"edges\": np.array(edges, dtype=np.float64),\n",
        "      \"receivers\": np.array(receivers, dtype=np.float64),\n",
        "      \"senders\": np.array(senders, dtype=np.float64)\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "fflJID-9pWJv"
      },
      "source": [
        "#@title Flip Functions \n",
        "#@markdown These functions propagate the failure across the graph\n",
        "def flip_edges(graph):\n",
        "    nodes = graph.nodes.numpy()\n",
        "    edges = graph.edges.numpy()\n",
        "    senders = graph.senders.numpy()\n",
        "\n",
        "    saturated_nodes = []\n",
        "    bad_latency_nodes = []\n",
        "    bad_traffic_nodes = []\n",
        "    traffic_on_node = []\n",
        "    for i in range(len(nodes)):\n",
        "        ns = node_status(nodes[i])\n",
        "        \n",
        "        if ns.saturation:\n",
        "            saturated_nodes.append(i)\n",
        "            # 3- Saturation causes Latency on the same node in the next step.\n",
        "            nodes[i] = set_latency(nodes[i], 1)\n",
        "        if ns.latency: \n",
        "            bad_latency_nodes.append(i)\n",
        "        if ns.traffic:\n",
        "            bad_traffic_nodes.append(i)\n",
        "            traffic_on_node.append(nodes[i][6:])\n",
        "            set_traffic(nodes[i], ns.traffic) \n",
        "\n",
        "    for ix, sender in enumerate(senders):\n",
        "        # 2 - Saturation causes immediate low traffic on downstreams in the same step.\n",
        "        if sender in set(saturated_nodes):\n",
        "            edges[ix] = set_edge_traffic(edges[ix], 0)\n",
        "        \n",
        "        if sender in set(low_traffic_nodes):\n",
        "            edges[ix] = set_edge_traffic(edges[ix], 0)\n",
        "            \n",
        "        if sender in bad_latency_nodes:\n",
        "            edges[ix] = set_latency(edges[ix], 1)\n",
        "\n",
        "    return graph.replace(\n",
        "        nodes=tf.convert_to_tensor(nodes),\n",
        "        edges=tf.convert_to_tensor(edges)\n",
        "    )\n",
        "\n",
        "def flip_nodes(graph):\n",
        "    nodes = graph.nodes.numpy()\n",
        "    edges = graph.edges.numpy()\n",
        "    receivers = graph.receivers.numpy()\n",
        "    senders = graph.senders.numpy()\n",
        "\n",
        "# 1- High traffic causes Saturation on the same node in the next step.\n",
        "# 2- Saturation causes immediate low traffic on downstreams in the same step.\n",
        "# 3- Saturation causes Latency on the same node in the next step.\n",
        "# 4- Latency causes Latency on the upstreams in the next step.\n",
        "# 5- Latency causes Errors on the same node in the next step.\n",
        "# 6- Latency causes Errors on the downstreams in the next step.\n",
        "# 7- Low traffic causes Low traffic on the downstreams in the next step.\n",
        "# 8- Errors cause Errors on the downstreams in the next step.\n",
        "    for ix in range(len(edges)):\n",
        "        estatus = edge_status(edges[ix])\n",
        "\n",
        "        node_idx = senders[ix]\n",
        "        nstatus = node_status(nodes[node_idx])\n",
        "        # 1- High traffic causes Saturation on the same node in the next step.\n",
        "        if nstatus.traffic == 2:\n",
        "          nodes[node_idx] = set_saturation(nodes[node_idx], 1)\n",
        "\n",
        "        # # 2- Saturation causes immediate low traffic on downstreams in the same step.\n",
        "        # if nstatus.saturation:\n",
        "        #   nodes[node_idx] = set_traffic(nodes[node_idx], 0)\n",
        "\n",
        "        # 3- Saturation causes Latency on the same node in the next step.\n",
        "        if nstatus.saturation:\n",
        "          nodes[node_idx] = set_latency(nodes[node_idx], 1)\n",
        "        \n",
        "        # 4- Latency causes Latency on the upstreams in the next step.\n",
        "        if estatus.latency: \n",
        "            node_idx = senders[ix]\n",
        "            nodes[node_idx] = set_latency(nodes[node_idx], 1)\n",
        "\n",
        "        if nstatus.latency:\n",
        "          # 5 - Latency causes Errors on the same node in the next step.\n",
        "          node_idx = senders[ix]\n",
        "          nodes[node_idx] = set_error(nodes[node_idx], 1)\n",
        "\n",
        "          # 6 - Latency causes Errors on the downstreams in the next step.\n",
        "          node_idx = receivers[ix]\n",
        "          nodes[node_idx] = set_error(nodes[node_idx], 1)\n",
        "\n",
        "        # 7 - Low traffic causes Low traffic on the downstreams in the next step.\n",
        "        if estatus.traffic == 0: \n",
        "            node_idx = receivers[ix]\n",
        "            nodes[node_idx] = set_traffic(nodes[node_idx], 0)\n",
        "\n",
        "        # 8- Errors cause Errors on the downstreams in the next step.\n",
        "        if nstatus.errors: \n",
        "            node_idx = receivers[ix]\n",
        "            nodes[node_idx] = set_error(nodes[node_idx], 1)\n",
        "\n",
        "    return graph.replace(\n",
        "        nodes=tf.convert_to_tensor(nodes),\n",
        "        edges=tf.convert_to_tensor(edges)\n",
        "    ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsLOXQ-yclkk"
      },
      "source": [
        "### Testing\n",
        "create a simple graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LiEpJtjlw9"
      },
      "source": [
        "# 3 nodes and 3 edges\n",
        "data_dict = create_graph_dict(3, 3,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXowQjuJk0VX"
      },
      "source": [
        "data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi8rromfkh7U"
      },
      "source": [
        "#@title convert it to GraphTuple\n",
        "graph_tuple = utils_tf.data_dicts_to_graphs_tuple([data_dict])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUVmU3ZamnMr"
      },
      "source": [
        "#@title plot it\n",
        "plot_graphs_tuple(graph_tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFknKigg5BVs"
      },
      "source": [
        "stage1 = flip_edges(graph_tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQn71yIIrDj1"
      },
      "source": [
        "plot_graphs_tuple(stage1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cblk3oVKhp2o"
      },
      "source": [
        "stage2 = flip_nodes(stage1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWgL4E0AtMG2"
      },
      "source": [
        "plot_graphs_tuple(stage2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e1yqbLpuInC"
      },
      "source": [
        "Now we want to update the receiver node at the next step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50syDjNvTT_"
      },
      "source": [
        "stage3 = flip_edges(stage2)\n",
        "plot_graphs_tuple(stage3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVFFvR_3lw5M"
      },
      "source": [
        "stage4 = flip_nodes(stage3)\n",
        "plot_graphs_tuple(stage4)\n",
        "stage5 = flip_edges(stage4)\n",
        "plot_graphs_tuple(stage5)\n",
        "stage5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlybsOjMoeHw"
      },
      "source": [
        "stage6 = flip_nodes(stage5)\n",
        "plot_graphs_tuple(stage6)\n",
        "stage7 = flip_edges(stage6)\n",
        "plot_graphs_tuple(stage7)\n",
        "stage7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlbjhYtvz4DG"
      },
      "source": [
        "def encode_state(l=0, e=0, s=0, t=0):\n",
        "  n3 = np.eye(3)\n",
        "  stage3 = flip_edges(stage2)\n",
        "  plot_graphs_tuple(stage3)\n",
        "  n2 = np.eye(2)\n",
        "  return np.concatenate((n2[l], n2[e], n2[s], n3[t]), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsKMY4Qz5W_"
      },
      "source": [
        "encode_state(t=1, s=1, l=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOkVHp-80u8M"
      },
      "source": [
        "encode_state(l=1, s=1, t=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj7t4otTAU19"
      },
      "source": [
        "import typing\n",
        "\n",
        "class Scenario(object):\n",
        "  def __init__(self, name):\n",
        "    self._graph_nx = nx.OrderedMultiDiGraph()\n",
        "    self._count: int = 0\n",
        "    self._name = name\n",
        "    self._map = {}\n",
        "\n",
        "  def add_node(self, name, l=0, e=0, s=0, t=1):\n",
        "    \"\"\"\n",
        "    l: Latency (low=0, high=1)\n",
        "    e: Error (no errors=0, errors=1)\n",
        "    s: Saturation (low=0, high=1)\n",
        "    t: Traffic (low=0, medium=1, high=2)\n",
        "    \"\"\"\n",
        "    f = encode_state(l=l, e=e, s=s, t=t)\n",
        "    self._graph_nx.add_node(self._count, \n",
        "                                label=name, \n",
        "                                features=f)\n",
        "    node = tuple((name, self._count, f))\n",
        "    self._map[self._count] = name\n",
        "    self._count += 1\n",
        "    return node\n",
        "  \n",
        "  def set_traffic(self, node, t=0):\n",
        "    idx = node[1]\n",
        "    self._graph_nx.nodes[idx]['features'] = set_traffic(self._graph_nx.nodes[idx]['features'], t)\n",
        "    return self\n",
        "\n",
        "  def set_saturation(self, node, s=0):\n",
        "    idx = node[1]\n",
        "    self._graph_nx.nodes[idx]['features'] = set_saturation(self._graph_nx.nodes[idx]['features'], s)\n",
        "    return self\n",
        "  \n",
        "  def set_latency(self, node, l=0):\n",
        "    idx = node[1]\n",
        "    self._graph_nx.nodes[idx]['features'] = set_latency(self._graph_nx.nodes[idx]['features'], l)\n",
        "    return self\n",
        "  \n",
        "  def set_error(self, node, e=0):\n",
        "    idx = node[1]\n",
        "    self._graph_nx.nodes[idx]['features'] = set_error(self._graph_nx.nodes[idx]['features'], e)\n",
        "    return self\n",
        "\n",
        "  def connect(self, a, b, l=0, t=0):\n",
        "    f = healthy_edge()\n",
        "    self._graph_nx.add_edge(a[1], b[1], features=f)\n",
        "    return\n",
        "\n",
        "  def _repr_pretty_(self, p, cycle, pos=0):\n",
        "    ax = plt.figure(figsize=(3, 3)).gca()\n",
        "    #nx.draw(self._graph_nx, ax=ax, with_labels=True)\n",
        "    #ax.set_title(self._name)\n",
        "    #plot_graph_networkx(self._graph_nx, ax=ax)\n",
        "    graph = self._graph_nx \n",
        "    \n",
        "    node_color_map = [node_color(node, data) for node, data in graph.nodes(data=True)]\n",
        "    edge_color_map = [edge_color(sender, receiver, data) for sender, receiver, data in graph.edges(data=True)]\n",
        "    \n",
        "    random_pos = nx.random_layout(graph, seed=42)\n",
        "    pos = nx.spring_layout(graph, pos=random_pos)\n",
        "  \n",
        "    nx.draw_networkx(graph, \n",
        "                     pos, \n",
        "                     ax=ax, \n",
        "                     labels=self._map,\n",
        "                     edge_color=edge_color_map,\n",
        "                     node_color=node_color_map)\n",
        "    \n",
        "    edge_labels = None \n",
        "    if edge_labels:\n",
        "      nx.draw_networkx_edge_labels(graph, pos, edge_labels, ax=ax)\n",
        "\n",
        "    global_label = None  \n",
        "    if global_label:\n",
        "      plt.text(0.05, 0.95, global_label, transform=ax.transAxes)\n",
        "  \n",
        "    ax.yaxis.set_visible(False)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    return ax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VbdA3PJAFBu"
      },
      "source": [
        "#@title Build Graph Manually\n",
        "scenario = Scenario(name=\"Short failing node due to high traffic\")\n",
        "\n",
        "A = scenario.add_node('A', l=0, e=0, s=0, t=1)\n",
        "B = scenario.add_node('B', l=0, e=0, s=0, t=0)\n",
        "C = scenario.add_node('C', l=0, e=0, s=0, t=0)\n",
        "D = scenario.add_node('D', l=0, e=0, s=0, t=0)\n",
        "scenario.connect(A, B)\n",
        "scenario.connect(B, C)\n",
        "scenario.connect(A, D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA0bEyRYuZp2"
      },
      "source": [
        "scenario"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk7OJwx250Sz"
      },
      "source": [
        "scenario.set_traffic(B, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eAY2m9IB4yV"
      },
      "source": [
        "graphs_tuple = utils_np.networkxs_to_graphs_tuple([scenario._graph_nx])\n",
        "graphs_tuple = utils_tf.data_dicts_to_graphs_tuple(utils_np.graphs_tuple_to_data_dicts(graphs_tuple))\n",
        "plot_graphs_tuple(graphs_tuple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjpqxwCjswSF"
      },
      "source": [
        "steps = 8\n",
        "state = graphs_tuple\n",
        "for i in range(steps):\n",
        "  state = flip_nodes(state)\n",
        "  plot_graphs_tuple(state)\n",
        "  state = flip_edges(state)\n",
        "  plot_graphs_tuple(state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtpDaP9fc4Q0"
      },
      "source": [
        "# Simulator\n",
        "\n",
        "With this logic we can create our desired simulator that updates the graph as a failure propagation across the nodes at each timestep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XW_z-0eM6aZ"
      },
      "source": [
        "def simulator(initial_state, steps):\n",
        "    current_state = initial_state\n",
        "    records = [ copy.copy(initial_state) ]\n",
        "    for s in range(steps):\n",
        "        if s % 2 == 1:\n",
        "            current_state = flip_nodes(current_state)\n",
        "        else:\n",
        "            current_state = flip_edges(current_state)\n",
        "        # propagate node value to outgoing edges\n",
        "        records.append(copy.copy(current_state))\n",
        "    return records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDDMwPKbE0xL"
      },
      "source": [
        "test_graph_dict = create_graph_dict(5, 6,1)\n",
        "test_graph = utils_tf.data_dicts_to_graphs_tuple([test_graph_dict])\n",
        "graph_at_timestep = simulator(test_graph, steps=10)\n",
        "plot_compare_graphs(graph_at_timestep, [ f\"stage{i}\" for i in range(10+1) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhR9y7efN8e0"
      },
      "source": [
        "stage0_dict = create_graph_dict(3, 3,1)\n",
        "stage0 = utils_tf.data_dicts_to_graphs_tuple([stage0_dict])\n",
        "stage1 = flip_nodes(stage0)\n",
        "plot_graphs_tuple(stage1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao4_XMfmc_Cp"
      },
      "source": [
        "Now let's run the simulator for N steps and see how it updates the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnkdW7NMNVTC"
      },
      "source": [
        "TIMESTEPS=5\n",
        "graph_at_timestep = simulator(stage0, steps=TIMESTEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbRuFiUgNZRY"
      },
      "source": [
        "plot_compare_graphs(graph_at_timestep, [ f\"stage{i}\" for i in range(TIMESTEPS+1) ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7I__V5zQx5G"
      },
      "source": [
        "Let's try more complex graphs with more nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvzmhz1lQ27Y"
      },
      "source": [
        "# #@title sample with 5 nodes and 5 edges\n",
        "# sample_graph = create_graph_dict(5, 5,1)\n",
        "# graph_tuple = utils_tf.data_dicts_to_graphs_tuple([sample_graph])\n",
        "# ## seems we have to flip always the first \n",
        "# results = simulator(graph_tuple, steps=int(graph_tuple.n_node.numpy()))\n",
        "# plot_compare_graphs(results, [ f\"step{i}\" for i in range(10) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPS2yliZdTvY"
      },
      "source": [
        "# #@title sample with 6 nodes and 10 edges\n",
        "# sample_graph = create_graph_dict(6, 10,1)\n",
        "# graph_tuple = utils_tf.data_dicts_to_graphs_tuple([sample_graph])\n",
        "# results = simulator(graph_tuple, steps=int(graph_tuple.n_node.numpy()))\n",
        "# plot_compare_graphs(results, [ f\"step{i}\" for i in range(10) ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BihR7amvgI9R"
      },
      "source": [
        "graph_tuple.senders.shape, graph_tuple.receivers.shape, graph_tuple.edges.shape, graph_tuple.nodes.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmoEXf1Zg8mW"
      },
      "source": [
        "graph_tuple.senders.shape, graph_tuple.receivers.shape, graph_tuple.edges.shape, graph_tuple.nodes.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2qdxlP3wYHD"
      },
      "source": [
        "# Create the Model\n",
        "\n",
        "## Questions\n",
        "\n",
        "- When does the model break?\n",
        "- How many steps can we simulate?\n",
        "- How many nodes can we generalize over? (range)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NEJ4EDRyUGG"
      },
      "source": [
        "# Loss Function\n",
        "The training loss is computed on the output of each processing step. \n",
        "\n",
        "The reason for this is to encourage the model to try to solve the problem in as\n",
        "few steps as possible. \n",
        "\n",
        "It also helps make the output of intermediate steps more interpretable\n",
        "\n",
        "The loss is computed only on the final processing step.\n",
        "\n",
        "For each node and edge we want to compute the classification error using the crossentropy loss \n",
        "\n",
        "$y log(p)+(1-y)log(1-p)$ \n",
        "\n",
        "The loss for each step is the sum of the losses for each node, plus the sum of the losses for each edge.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "bkKTAc51BVuy"
      },
      "source": [
        "#@title Loss Function\n",
        "\n",
        "cross_entropy = tf.losses.categorical_crossentropy\n",
        "\n",
        "def create_loss(target, predicted, **kwds):\n",
        "    \"\"\"\n",
        "    sum of the crosspentropy loss for the edges and the nodes\n",
        "\n",
        "    Args:\n",
        "        target: a `graphs.GraphsTuple` which contains the target as a graph.\n",
        "        predicted: a `list` of `graphs.GraphsTuple`s which contains the model\n",
        "            outputs for each processing step as graphs.\n",
        "\n",
        "    Returns:\n",
        "        A `list` of ops which are the loss for each processing step. \n",
        "    \"\"\"\n",
        "    # this is the list of the mean losses for each timestep\n",
        "    # + label smoothing to help the learning phase\n",
        "    losses = [ \n",
        "            tf.math.reduce_sum(\n",
        "                tf.concat( [\n",
        "                    cross_entropy(target.nodes[:, 0:2], output.nodes[:, 0:2], **kwds), # latency \n",
        "                    cross_entropy(target.nodes[:, 2:4], output.nodes[:, 2:4], **kwds),  # error\n",
        "                    cross_entropy(target.nodes[:, 4:6], output.nodes[:, 4:6], **kwds),  # saturation \n",
        "                    cross_entropy(target.nodes[:, 6:], output.nodes[:, 6:], **kwds)  # traffic\n",
        "                ], axis=0)\n",
        "              ) \n",
        "        +\n",
        "            tf.math.reduce_sum(\n",
        "              tf.concat([\n",
        "                cross_entropy(target.edges[:, 0:2], output.edges[:, 0:2], **kwds), \n",
        "                cross_entropy(target.edges[:, 2:], output.edges[:, 2:], **kwds)\n",
        "              ], axis=0))\n",
        "    for output in predicted ]\n",
        "\n",
        "    return losses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "EF7cYOlYVn2p"
      },
      "source": [
        "#@title Accuracy \n",
        "def compute_accuracy(target, output):\n",
        "  \"\"\"Calculate model accuracy.\n",
        "\n",
        "  Returns the number of correctly predicted nodes and the number\n",
        "  of predicted edges\n",
        "\n",
        "  Args:\n",
        "    target: A `graphs.GraphsTuple` that contains the target graph.\n",
        "    output: A `graphs.GraphsTuple` that contains the output graph.\n",
        "\n",
        "  Returns:\n",
        "    correct: A `float` fraction of correctly labeled nodes.\n",
        "    solved: A `float` fraction of graphs that are completely correctly labeled.\n",
        "  \"\"\"\n",
        "  tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
        "  odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
        "  cs = []\n",
        "  ss = []\n",
        "  for td, od in zip(tdds, odds):\n",
        "    latency_xn = np.argmax(td[\"nodes\"][:, 0:2], axis=-1)\n",
        "    latency_yn = np.argmax(od[\"nodes\"][:, 0:2], axis=-1)\n",
        "    \n",
        "    errors_xn = np.argmax(td[\"nodes\"][:, 2:4], axis=-1)\n",
        "    errors_yn = np.argmax(od[\"nodes\"][:, 2:4], axis=-1)\n",
        "    \n",
        "    saturation_xn = np.argmax(td[\"nodes\"][:, 4:6], axis=-1)\n",
        "    saturation_yn = np.argmax(od[\"nodes\"][:, 4:6], axis=-1)\n",
        "    \n",
        "    traffic_xn = np.argmax(td[\"nodes\"][:, 6:], axis=-1)\n",
        "    traffic_yn = np.argmax(od[\"nodes\"][:, 6:], axis=-1)\n",
        "    \n",
        "    latency_xe = np.argmax(td[\"edges\"][:, 0:2], axis=-1)\n",
        "    latency_ye = np.argmax(od[\"edges\"][:, 0:2], axis=-1)\n",
        "    \n",
        "    traffic_xe = np.argmax(td[\"edges\"][:, 2:], axis=-1)\n",
        "    traffic_ye = np.argmax(od[\"edges\"][:, 2:], axis=-1)\n",
        "\n",
        "\n",
        "    # if the train node value is equal to the true node value\n",
        "    # if the edge node value is equal to the true edge value\n",
        "    # correct edges and nodes\n",
        "    c = np.concatenate((latency_xn == latency_yn, \n",
        "                        errors_xn == errors_yn, \n",
        "                        saturation_xn == saturation_yn,\n",
        "                        traffic_xn == traffic_yn,\n",
        "                        traffic_xe == traffic_ye,\n",
        "                        latency_xe == latency_ye), \n",
        "                       axis=0)\n",
        "    # solved\n",
        "    s = np.all(c)\n",
        "    cs.append(c)\n",
        "    ss.append(s)\n",
        "  correct = np.mean(np.concatenate(cs, axis=0))\n",
        "  solved = np.mean(np.stack(ss))\n",
        "  return correct, solved\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuW0BoFLzWx5"
      },
      "source": [
        "\n",
        "- **Ltr**: training loss\n",
        "- **Lge**: test/generalization loss\n",
        "      \n",
        "- **Ctr**: training fraction nodes/edges labeled correctly\n",
        "\n",
        "- **Str**: training fraction examples solved correctly\n",
        "\n",
        "- **Cge**: test/generalization fraction nodes/edges labeled correctly \n",
        "\n",
        "- **Sge**: test/generalization fraction examples solved correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_MoX6xfPIp1"
      },
      "source": [
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1BeUXjAO6yJ"
      },
      "source": [
        "#@title # Reset State \n",
        "try:\n",
        "    del model\n",
        "except:\n",
        "    pass\n",
        "gc.collect()\n",
        "\n",
        "NUM_PROCESSING_STEPS=10 #@param \n",
        "\n",
        "#@markdown # Data / training parameters\n",
        "# num_training_iterations = 50000 #@param \n",
        "BATCH_SIZE_TRAIN = 32 #@param \n",
        "BATCH_SIZE_VAL = 100 #@param\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVGmYjAC98EU"
      },
      "source": [
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "def make_mlp_model(latent_size, num_layers, final_output_size):\n",
        "  \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
        "  The parameters of each new MLP are not shared with others generated by\n",
        "  this function.\n",
        "  Returns:\n",
        "    A Sonnet module which contains the MLP and LayerNorm.\n",
        "  \"\"\"\n",
        "  return snt.Sequential([\n",
        "      snt.nets.MLP(output_sizes=[latent_size] * num_layers + [final_output_size], activate_final=True),\n",
        "      snt.LayerNorm(axis=-1, create_offset=True, create_scale=True)\n",
        "  ])\n",
        "\n",
        "#@title Interaction Network module\n",
        "# the reducer is sum as is the sum of all the traffic in input\n",
        "from graph_nets.modules import InteractionNetwork\n",
        "import functools\n",
        "\n",
        "NUM_EDGE_FEATURES = 2 + 3 \n",
        "NUM_NODE_FEATURES = 2 + 2 + 2 + 3\n",
        "\n",
        "# edge_model_fn = functools.partial(make_mlp_model, \n",
        "#                                   latent_size=64, \n",
        "#                                   num_layers=10, \n",
        "#                                   final_output_size=NUM_EDGE_FEATURES) \n",
        "\n",
        "# node_model_fn = functools.partial(make_mlp_model, \n",
        "#                                   latent_size=64, \n",
        "#                                   num_layers=20, \n",
        "#                                   final_output_size=NODE_FEATURES_DIM)\n",
        "\n",
        "# model = InteractionNetwork(edge_model_fn, \n",
        "#                            node_model_fn, \n",
        "#                            reducer=tf.math.unsorted_segment_sum)\n",
        "\n",
        "\n",
        "# Model\n",
        "model = models.EncodeProcessDecode(edge_output_size=NUM_EDGE_FEATURES, \n",
        "                                   node_output_size=NUM_NODE_FEATURES, \n",
        "                                   global_output_size=None)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_57cpAzA1Zk"
      },
      "source": [
        "#@title Setup Optimizer, GraphNetwork\n",
        "learning_rate = 0.001 #@param\n",
        "optimizer = snt.optimizers.Adam(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "imXgeFr3Aqps"
      },
      "source": [
        "#@title Update Step, this function updates the weights of our model based on the loss\n",
        "\n",
        "# def update_step(inputs, targets):\n",
        "#   with tf.GradientTape() as tape:\n",
        "#     output = model(inputs)\n",
        "#     list_loss = create_loss(targets, [output], from_logits=True)\n",
        "#     # sum the losses of each step and averages over the number of steps\n",
        "#     # total_loss = tf.math.reduce_sum(list_loss) / NUM_PROCESSING_STEPS \n",
        "#     total_loss = tf.math.reduce_sum(list_loss)\n",
        "\n",
        "#   gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "#   optimizer.apply(gradients, model.trainable_variables)\n",
        "#   return [output], total_loss, list_loss\n",
        "\n",
        "def update_step(inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    output = model(inputs, NUM_PROCESSING_STEPS)\n",
        "    list_loss = create_loss(targets, output, from_logits=True)\n",
        "    # sum the losses of each step and averages over the number of steps\n",
        "    # total_loss = tf.math.reduce_sum(list_loss) / NUM_PROCESSING_STEPS \n",
        "    total_loss = tf.math.reduce_sum(list_loss) / NUM_PROCESSING_STEPS\n",
        "\n",
        "  gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "  optimizer.apply(gradients, model.trainable_variables)\n",
        "  return output, total_loss, list_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKAWqHswgQ2G"
      },
      "source": [
        "# Test update step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcZ2ZEcmQsC_"
      },
      "source": [
        "NUM_NODES = 10\n",
        "NUM_EDGES = 15\n",
        "g = create_graph_dict(NUM_NODES, NUM_EDGES,1)\n",
        "gt = utils_tf.data_dicts_to_graphs_tuple([g])\n",
        "gt_list = simulator(gt, NUM_PROCESSING_STEPS)\n",
        "\n",
        "# batch with only the last element\n",
        "gt_truth = gt_list[-1]\n",
        "\n",
        "input_batch = utils_tf.concat([gt], axis=0)\n",
        "target_batch = utils_tf.concat([gt_truth], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mvF9RJV9M07"
      },
      "source": [
        "def create_example(num_nodes, num_edges, i,timesteps=NUM_PROCESSING_STEPS):\n",
        "    g = create_graph_dict(num_nodes, num_edges,i)\n",
        "    gt = utils_tf.data_dicts_to_graphs_tuple([g])\n",
        "    \n",
        "    # simulate the failure propagation\n",
        "    g_list = simulator(gt, steps=timesteps)\n",
        "    gt_final_state = g_list[-1]\n",
        "    return gt, gt_final_state\n",
        "\n",
        "\n",
        "def gen_batch(batch_size):\n",
        "    # Compute a random graph. \n",
        "    # NOTE: We need a better heuristic to generate graphs that \n",
        "    #       represent interesting cases for our problem\n",
        "    inputs_batch = []\n",
        "    targets_batch = []\n",
        "\n",
        "    num_nodes = NUM_NODES\n",
        "    num_edges = NUM_EDGES\n",
        "    for i in range(batch_size):\n",
        "        g = create_graph_dict(num_nodes, num_edges,i)\n",
        "        gt = utils_tf.data_dicts_to_graphs_tuple([g])\n",
        "        \n",
        "        # simulate the failure propagation\n",
        "        gt_list = simulator(gt, steps=NUM_PROCESSING_STEPS)\n",
        "        inputs_batch.append(gt)\n",
        "        targets_batch.append(gt_list[-1])\n",
        "\n",
        "    inputs_tf_batch = utils_tf.concat(inputs_batch, axis=0)\n",
        "    targets_tf_batch = utils_tf.concat(targets_batch, axis=0)\n",
        "    return inputs_tf_batch, targets_tf_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD_deqCI9Q4V"
      },
      "source": [
        "input_batch, target_batch = gen_batch(BATCH_SIZE_TRAIN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xqv-383LdOA"
      },
      "source": [
        "len(input_batch[0]), len(target_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt5Ieh8m_AuC"
      },
      "source": [
        "# Get the input signature for that function by obtaining the specs\n",
        "batch_input_signature = [\n",
        "  utils_tf.specs_from_graphs_tuple(input_batch),\n",
        "  utils_tf.specs_from_graphs_tuple(target_batch)\n",
        "]\n",
        "\n",
        "# Compile the update function using the input signature for speedy code.\n",
        "compiled_batch_update_step = tf.function(update_step, input_signature=batch_input_signature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGYhYaIpijlB"
      },
      "source": [
        "Let's optimize a single graph update function for debugging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpR7NkbMTT8d"
      },
      "source": [
        "#@title Compile single graph update step\n",
        "gt, gt_truth = create_example(NUM_NODES, NUM_EDGES,1)\n",
        "\n",
        "single_input_signature = [\n",
        "  utils_tf.specs_from_graphs_tuple(gt),\n",
        "  utils_tf.specs_from_graphs_tuple(gt_truth)\n",
        "]\n",
        "\n",
        "single_compiled_update_step = tf.function(update_step, \n",
        "                                          input_signature=single_input_signature)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSKcXBsMNMmH"
      },
      "source": [
        "## Test Step by Step Single Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pTlZEw9Us0k"
      },
      "source": [
        "g_in, g_out = create_example(NUM_NODES, NUM_EDGES,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw0_V79sUyz9"
      },
      "source": [
        "plot_compare_graphs([g_in, g_out], [\"input\", \"output\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGrgTWC2Ul2V"
      },
      "source": [
        "# train for a bit\n",
        "for i in range(10):\n",
        "    print(i)\n",
        "    steps, loss, list_loss = single_compiled_update_step(g_in, g_out)\n",
        "    labels = [ f\"loss:{v.numpy()}\" for v in list_loss]\n",
        "    #plot_compare_graphs(steps, labels)\n",
        "    # print(compute_accuracy(g_out, steps[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq8E8YotOc"
      },
      "source": [
        "g_in, g_out = create_example(NUM_NODES, NUM_EDGES,1)\n",
        "plot_compare_graphs([g_in, g_out], [\"input\", \"output\"])\n",
        "results = model(g_in, NUM_PROCESSING_STEPS)\n",
        "plot_compare_graphs([results[-1], g_out], [\"result\", \"target\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVeOB5ypwNnk"
      },
      "source": [
        "compute_accuracy(results[-1], g_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDmIZw88ZP4l"
      },
      "source": [
        "#@title sample with 5 nodes and 5 edges\n",
        "sample_graph = create_graph_dict(5, 6, 0)\n",
        "graph_tuple = utils_tf.data_dicts_to_graphs_tuple([sample_graph])\n",
        "## seems we have to flip always the first \n",
        "results = simulator(graph_tuple, steps=9)\n",
        "plot_compare_graphs(results, [ f\"step{i}\" for i in range(10) ])\n",
        "# results = simulator(results[-1], steps=4)\n",
        "# plot_compare_graphs(results, [ f\"step{i+5}\" for i in range(5) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZcmqddHPv7S"
      },
      "source": [
        "\n",
        "# LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oilFRDSAsJ1y"
      },
      "source": [
        "#@title init state\n",
        "last_iteration = 0\n",
        "logged_iterations = []\n",
        "losses_tr = []\n",
        "corrects_tr = []\n",
        "solveds_tr = []\n",
        "losses_ge = []\n",
        "corrects_ge = []\n",
        "solveds_ge = []\n",
        "\n",
        "log_every_seconds =  10#@param\n",
        "num_processing_steps_tr = 10 #@param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eykAkZ1eB1Ql"
      },
      "source": [
        "from tqdm import auto as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "gOcsvvwUpvZM"
      },
      "source": [
        "#@title Train Loop\n",
        "num_training_iterations = 3000\n",
        "start_time = time.time()\n",
        "last_log_time = start_time\n",
        "for iteration in tqdm.tqdm(range(last_iteration, num_training_iterations)):\n",
        "  last_iteration = iteration\n",
        "  n_nodes, n_edges = NUM_NODES , NUM_EDGES\n",
        "\n",
        "  # outputs_tr, loss_tr = compiled_update_step(inputs_tr, targets_tr)\n",
        "  g_in, g_out = create_example(n_nodes, n_edges,iteration)\n",
        "\n",
        "  outputs_tr, total_loss_tr, _ = single_compiled_update_step(g_in, g_out)\n",
        "\n",
        "  the_time = time.time()\n",
        "  elapsed_since_last_log = the_time - last_log_time\n",
        "\n",
        "  # keep looping \n",
        "  if elapsed_since_last_log <= log_every_seconds: continue\n",
        "\n",
        "  # LOG \n",
        "  num_processing_steps_ge = num_processing_steps_tr\n",
        "  g_val_in, g_val_out = create_example(n_nodes+1, n_edges+2,iteration)\n",
        "\n",
        "  last_log_time = the_time\n",
        "  outputs_val = model(g_val_in, NUM_PROCESSING_STEPS)\n",
        "  loss_list = create_loss(g_val_out, outputs_val)\n",
        "  loss_ge = loss_list[-1]\n",
        "\n",
        "  # outputs_ge is a list of N * batch_size graphs\n",
        "  \n",
        "  # plot_compare_graphs( [outputs_val, g_val_out], \n",
        "  #                     [ \"result\", \"ground truth\"])\n",
        "  \n",
        "  # correct_tr, solved_tr = compute_accuracy(g_out, outputs_tr[-1])\n",
        "  correct_tr, solved_tr = compute_accuracy(g_out, outputs_tr[-1])\n",
        "  correct_ge, solved_ge = compute_accuracy(g_val_out, outputs_val[-1])\n",
        "  \n",
        "  elapsed = time.time() - start_time\n",
        "  # train\n",
        "  losses_tr.append(total_loss_tr.numpy())\n",
        "  corrects_tr.append(correct_tr)\n",
        "  solveds_tr.append(solved_tr)\n",
        "  # val\n",
        "  losses_ge.append(loss_ge.numpy())\n",
        "  corrects_ge.append(correct_ge)\n",
        "  solveds_ge.append(solved_ge)\n",
        "\n",
        "  logged_iterations.append(iteration)\n",
        "  print(\"# {:05d}, T {:05.1f}, Ltr {:.4f}, Lge {:.4f}, Ctr {:.4f}, \"\n",
        "          \"Str {:.4f}, Cge {:.4f}, Sge {:.4f}\".format(\n",
        "              iteration, elapsed, total_loss_tr.numpy(), loss_ge.numpy(),\n",
        "              correct_tr, solved_tr, correct_ge, solved_ge))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v42e7P8BloVY"
      },
      "source": [
        "print(\"Training overall:\")\n",
        "print(\"Number of evaluated models: \"+str(len(corrects_tr)))\n",
        "print(corrects_tr)\n",
        "print(solveds_tr)\n",
        "average = sum(corrects_tr) / len(corrects_tr)\n",
        "print(\"The average of correct classified nodes/edges (Training) \" + str(round(average, 2)))\n",
        "\n",
        "print(\"Generalization overall:\")\n",
        "print(\"Number of evaluated models: \"+str(len(corrects_ge)))\n",
        "print(corrects_ge)\n",
        "print(solveds_ge)\n",
        "average = sum(corrects_ge) / len(corrects_ge)\n",
        "print(\"The average of correct classified nodes/edges (Generaliztion) \" + str(round(average, 2)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTNZ9SpLAdIw"
      },
      "source": [
        "# print(\"# {:05d}, T {:05.1f} loss:train {:.4f} loss:gen {:.4f} correct:train {:.4f} \"\n",
        "#           \"solved:train {:.4f} correct:gen {:.4f} solved:gen {:.4f}\".format(\n",
        "#               iteration, elapsed, total_loss_tr.numpy(), loss_ge.numpy(),\n",
        "#               correct_tr, solved_tr, correct_ge, solved_ge))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOUu6DB4xcbG"
      },
      "source": [
        "## Manual Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89EKmKGRBF22"
      },
      "source": [
        "# results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-faH96Z-BNn"
      },
      "source": [
        "# MAX_ITERATIONS = 20\n",
        "# plot_compare_graphs([results], [ str(i) for i in range(MAX_ITERATIONS)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjnb17Laxeym"
      },
      "source": [
        "MAX_ITERATIONS = 10\n",
        "for node_variance in range(1, 10):\n",
        "    for edge_variance in range(1, 10):\n",
        "        g_in, g_out = create_example(NUM_NODES + node_variance, NUM_EDGES + edge_variance,1)\n",
        "        for timesteps in range(1, MAX_ITERATIONS+1):\n",
        "            results = model(g_in, timesteps)\n",
        "            correct, solved = compute_accuracy(results[-1], g_out)\n",
        "            if correct and solved:\n",
        "                print('solved in %d' % timesteps)\n",
        "                plot_compare_graphs([g_in, results[-1], g_out], [ \"input\", f\"Correct:{correct:.2f} Solved:{solved:.2f}\", \"target\"])\n",
        "                break\n",
        "            if timesteps == MAX_ITERATIONS:\n",
        "                print(\"not solved\")\n",
        "                plot_compare_graphs([g_in, results[-1], g_out], [ \"input\", f\"Correct:{correct:.2f} Solved:{solved:.2f}\", \"target\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ywV76TmXeG"
      },
      "source": [
        "accuracy_list=[]\n",
        "# the edge count shoud increase with the sqaure of the node size\n",
        "\n",
        "for i in range(1,  2):\n",
        "    g_in, g_out = create_example(100, 625,1)\n",
        "    results = model(g_in, NUM_PROCESSING_STEPS)\n",
        "    correct, solved = compute_accuracy(results[-1], g_out)\n",
        "    accuracy_list.append(correct)\n",
        "    plot_compare_graphs_custom([g_in, results[-1], g_out], [\"input\",\"Prediction\", \"Actual\"])\n",
        "    # if i > 990:\n",
        "    #   plot_compare_graphs([g_in, results[-1], g_out], [ \"input\", f\"Prediction Correct:{correct:.2f} Solved:{solved:.2f}\", \"Actual\"])\n",
        "\n",
        "print(\"1k nodes generalization:\")\n",
        "print(accuracy_list)\n",
        "average = sum(accuracy_list) / len(accuracy_list)\n",
        "print(\"The average of correct classified nodes/edges \" + str(round(average, 2)))         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvSXVoFPovLj"
      },
      "source": [
        "plt.plot(losses_tr)\n",
        "# plt.plot(accuracy_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KySTzS3K36SU"
      },
      "source": [
        "plt.figure(figsize=(50, 7))\n",
        "plt.plot(corrects_tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_K5peK018h"
      },
      "source": [
        "%watermark -d -t -n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zd8nErEBdyu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}